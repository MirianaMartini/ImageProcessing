# ImageProcessing

What drove us in the implementation of this project is the desire to enable people who are deaf
hearing people to communicate more easily. So we decided to make a small contribution by implementing
a prototype of a real-time virtual visual assistant capable of interpreting gestures from the alphabet of the
International Sign Language.
This assistant, implemented through the use of the MediaPipe framework and the OpenCV library, is
capable of recognizing and translating static gestures produced by the left hand in realtime with great ease,
as it requires only the use of a webcam.
However, being a prototype, it should be improved in terms of gesture recognition accuracy
and expanded to the interpretation of whole expressions or more complex phrases that require the movement
of the hand over time.

![image](https://user-images.githubusercontent.com/48263007/226966203-bbbd02e2-c685-4c11-946d-3d1e3a3f0870.png)
